{
    "address": "",
    "chat": "https://huggingface.co/gaianet/EXAONE-Deep-32B-GGUF/resolve/main/EXAONE-Deep-32B-Q5_K_M.gguf",
    "chat_ctx_size": "8192",
    "chat_batch_size": "64",
    "chat_name": "EXAONE-Deep-32B-Instruct-Q5_K_M",
    "description": "EXAONE-Deep-32B",
    "domain": "gaia.domains",
    "embedding": "https://huggingface.co/gaianet/Nomic-embed-text-v1.5-Embedding-GGUF/resolve/main/nomic-embed-text-v1.5.f16.gguf",
    "embedding_ctx_size": "8192",
    "embedding_batch_size": "8192",
    "embedding_name": "nomic-embed-text-v1.5.f16",
    "llamaedge_port": "8080",
    "prompt_template": "exaone-deep-chat",
    "rag_prompt": "Use the following pieces of context to answer the user's question.\n----------------\n",
    "reverse_prompt": "",
    "snapshot": "",
    "system_prompt": "You are a helpful, respectful, and honest assistant.",
    "rag_policy": "last-user-message",
    "embedding_collection_name": "default",
    "context_window": "1",
    "qdrant_limit": "1",
    "qdrant_score_threshold": "0.5"
  }
  
