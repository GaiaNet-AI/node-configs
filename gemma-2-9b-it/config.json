{
  "address": "",
  "chat": "https://huggingface.co/gaianet/gemma-2-9b-it-GGUF/resolve/main/gemma-2-9b-it-Q5_K_M.gguf",
  "chat_ctx_size": "8192",
  "chat_batch_size": "64",
  "chat_name": "gemma-2-9b-it-Q5_K_M",
  "description": "gemma-2-9b-it",
  "domain": "us.gaianet.network",
  "embedding": "https://huggingface.co/gaianet/Nomic-embed-text-v1.5-Embedding-GGUF/resolve/main/nomic-embed-text-v1.5.f16.gguf",
  "embedding_ctx_size": "8192",
  "embedding_batch_size": "8192",
  "embedding_name": "nomic-embed-text-v1.5.f16",
  "llamaedge_port": "8080",
  "prompt_template": "gemma-instruct",
  "rag_prompt": "Use the following pieces of context to answer the user's question.\n----------------\n",
  "reverse_prompt": "",
  "snapshot": "",
  "system_prompt": "You are a helpful, respectful, and honest assistant.",
  "rag_policy": "last-user-message",
  "embedding_collection_name": "default",
  "qdrant_limit": "1",
  "qdrant_score_threshold": "0.5"
}
