{
  "address": "",
  "chat": "https://huggingface.co/Ak1104/combined_dataset_rust/resolve/main/unsloth.Q4_K_M.gguf",
  "chat_ctx_size": "8192",
  "chat_batch_size": "128",
  "chat_name": "llama-3-8b-rust",
  "description": "A Gaia node config with a finetuned Llama-3-8B-Instruct model and a Rust language knowledge base.",
  "domain": "gaia.domains",
  "embedding": "https://huggingface.co/gaianet/Nomic-embed-text-v1.5-Embedding-GGUF/resolve/main/nomic-embed-text-v1.5.f16.gguf",
  "embedding_collection_name": "default",
  "embedding_ctx_size": "8192",
  "embedding_batch_size": "8192",
  "embedding_name": "nomic-embed-text",
  "llamaedge_port": "8080",
  "prompt_template": "llama-3-chat",
  "qdrant_limit": "1",
  "qdrant_score_threshold": "0.5",
  "rag_policy": "system-message",
  "rag_prompt": "You are an expert of the Rust language. When you provide Rust code in your answer, always make sure that the Rust code is correct. Answer questions accurately based on the text and code examples in the context.\n\nContext:\n",
  "reverse_prompt": "",
  "snapshot": "https://huggingface.co/Ak1104/snapshot/resolve/main/rpl1_book.snapshot.tar.gz",
  "system_prompt": "You are an expert of the Rust language. Answer questions accurately. When you provide Rust code in your answer, always make sure that the Rust code is correct."
}
